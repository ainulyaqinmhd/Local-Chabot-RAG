{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2WlziVvIcEVH9XMXWLofG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## RAG\n",
        "\n",
        "### Indexing\n",
        "1. **Load**: First we need to load our data. This is done with CSV Loaders\n",
        "2. **Split**: Text splitters break large Documents into smaller chunks. This is useful both for indexing data and for passing it in to a model, since large chunks are harder to search over and won't fit in a model's finite context window.\n",
        "3. **Store**: We need somewhere to store and index our splits, so that they can later be searched over. This is often done using a VectorStore and Embeddings model.\n",
        "\n",
        "### Retrieval and generation\n",
        "4. **Retrieve**: Given a user input, relevant splits are retrieved from storage using a Retriever.\n",
        "5. **Generate**: A ChatModel / LLM produces an answer using a prompt that includes the question and the retrieved data"
      ],
      "metadata": {
        "id": "_-uSwwvPfc7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package Installation"
      ],
      "metadata": {
        "id": "yL0ImVcY-x6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_community langchain_chroma langchain-openai langchainhub gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vqW5m8Nje4sR",
        "outputId": "690e76db-70c1-4a1c-fe30-a165f2bd6a00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.11-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain_chroma\n",
            "  Downloading langchain_chroma-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchainhub\n",
            "  Downloading langchainhub-0.1.20-py3-none-any.whl.metadata (659 bytes)\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.39.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.23 (from langchain)\n",
            "  Downloading langchain_core-0.2.24-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.93-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting chromadb<0.6.0,>=0.4.0 (from langchain_chroma)\n",
            "  Downloading chromadb-0.5.5-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting fastapi<1,>=0.95.2 (from langchain_chroma)\n",
            "  Downloading fastapi-0.111.1-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting openai<2.0.0,>=1.32.0 (from langchain-openai)\n",
            "  Downloading openai-1.37.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (24.1)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.32.0.20240712-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==1.1.1 (from gradio)\n",
            "  Downloading gradio_client-1.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.5.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.1.1->gradio) (2024.6.1)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==1.1.1->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.2.1)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting posthog>=2.4.0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.66.4)\n",
            "Collecting overrides>=7.3.1 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi<1,>=0.95.2->langchain_chroma)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi<1,>=0.95.2->langchain_chroma)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting email_validator>=2.0.0 (from fastapi<1,>=0.95.2->langchain_chroma)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.23->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.0.1)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain_chroma)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.16.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.2.2)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.13.1)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting importlib-metadata<=8.0.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.63.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_util_http-0.47b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (71.0.4)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.6.0)\n",
            "Downloading langchain-0.2.11-py3-none-any.whl (990 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.2.10-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_chroma-0.1.2-py3-none-any.whl (9.3 kB)\n",
            "Downloading langchain_openai-0.1.19-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchainhub-0.1.20-py3-none-any.whl (5.0 kB)\n",
            "Downloading gradio-4.39.0-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.1.1-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.2/318.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading chromadb-0.5.5-py3-none-any.whl (584 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fastapi-0.111.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.24-py3-none-any.whl (377 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.93-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.37.1-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.5.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl (11 kB)\n",
            "Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl (29 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl (15 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.47b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ffmpy, pypika\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=8090a89de129e55f158fe3fd57e566db61c35da7ceff66dbdb12a987d1ff8f66\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=d1e8847cc3740c58aa6cf0a85e1ef61ef3e5eaaa82f1a60fa3ef96205ac8a70c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built ffmpy pypika\n",
            "Installing collected packages: pypika, pydub, monotonic, mmh3, ffmpy, websockets, uvloop, types-requests, tomlkit, semantic-version, ruff, python-multipart, python-dotenv, overrides, orjson, opentelemetry-util-http, opentelemetry-proto, mypy-extensions, marshmallow, jsonpointer, importlib-metadata, humanfriendly, httptools, h11, dnspython, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, aiofiles, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, langchainhub, jsonpatch, httpcore, email_validator, coloredlogs, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, langsmith, kubernetes, httpx, dataclasses-json, opentelemetry-sdk, opentelemetry-instrumentation-asgi, openai, langchain-core, gradio-client, fastapi-cli, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-openai, fastapi, langchain, gradio, chromadb, langchain_community, langchain_chroma\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.0\n",
            "    Uninstalling tomlkit-0.13.0:\n",
            "      Successfully uninstalled tomlkit-0.13.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.1.0\n",
            "    Uninstalling importlib_metadata-8.1.0:\n",
            "      Successfully uninstalled importlib_metadata-8.1.0\n",
            "Successfully installed aiofiles-23.2.1 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 chroma-hnswlib-0.7.6 chromadb-0.5.5 coloredlogs-15.0.1 dataclasses-json-0.6.7 deprecated-1.2.14 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.1 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.39.0 gradio-client-1.1.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 importlib-metadata-8.0.0 jsonpatch-1.33 jsonpointer-3.0.0 kubernetes-30.1.0 langchain-0.2.11 langchain-core-0.2.24 langchain-openai-0.1.19 langchain-text-splitters-0.2.2 langchain_chroma-0.1.2 langchain_community-0.2.10 langchainhub-0.1.20 langsmith-0.1.93 marshmallow-3.21.3 mmh3-4.1.0 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.18.1 openai-1.37.1 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-instrumentation-0.47b0 opentelemetry-instrumentation-asgi-0.47b0 opentelemetry-instrumentation-fastapi-0.47b0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 opentelemetry-util-http-0.47b0 orjson-3.10.6 overrides-7.7.0 posthog-3.5.0 pydub-0.25.1 pypika-0.48.9 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.5.5 semantic-version-2.10.0 starlette-0.37.2 tiktoken-0.7.0 tomlkit-0.12.0 types-requests-2.32.0.20240712 typing-inspect-0.9.0 uvicorn-0.30.3 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use OpenAI API Key"
      ],
      "metadata": {
        "id": "fnAiukCs-0n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# Set the OpenAI API key for accessing the OpenAI services\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Initialize the ChatOpenAI object with the GPT-4 model\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n"
      ],
      "metadata": {
        "id": "8PQI2QNmexoN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data from CSV"
      ],
      "metadata": {
        "id": "bRRZsctV-3ua"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Pl1XM4peuDG",
        "outputId": "0fbc99b2-cafe-47ea-c996-c034a39897ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected columns in Database/Database with Financial Data and Addresses.csv: ['\\ufeffFund Name', 'Fund Manager Name', 'ISIN', 'Region', 'Sector', '2023 RE participants', 'Ticker_B', 'Ticker', '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', 'Address', 'Market']\n",
            "Loaded 270 documents from Database/Database with Financial Data and Addresses.csv\n",
            "Detected columns in Database/GRESB_fullArticlesVersion.csv: ['URL', 'Title', 'Content']\n",
            "Loaded 449 documents from Database/GRESB_fullArticlesVersion.csv\n",
            "Total documents loaded: 719\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "\n",
        "# Define the directory containing the database files\n",
        "database_folder = \"Database\"\n",
        "\n",
        "# List all files in the database folder\n",
        "files = [os.path.join(database_folder, f) for f in os.listdir(database_folder) if os.path.isfile(os.path.join(database_folder, f))]\n",
        "\n",
        "all_docs = []\n",
        "\n",
        "# Function to detect the structure of a CSV file\n",
        "def detect_csv_structure(file_path):\n",
        "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        header = next(reader)\n",
        "    return header\n",
        "\n",
        "# Load data from each CSV file in the folder\n",
        "for file in files:\n",
        "    if file.endswith(\".csv\"):\n",
        "        header = detect_csv_structure(file)\n",
        "        print(f\"Detected columns in {file}: {header}\")\n",
        "        source_column = \"URL\" if \"URL\" in header else header[0]  # Adjust source column as needed\n",
        "        loader = CSVLoader(\n",
        "            file_path=file,\n",
        "            source_column=source_column,\n",
        "            csv_args={\n",
        "                \"delimiter\": \",\",\n",
        "                \"quotechar\": '\"',\n",
        "                \"fieldnames\": header\n",
        "            }\n",
        "        )\n",
        "        docs = loader.load()\n",
        "        print(f\"Loaded {len(docs)} documents from {file}\")\n",
        "        all_docs.extend(docs)\n",
        "\n",
        "print(f\"Total documents loaded: {len(all_docs)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data to chunks"
      ],
      "metadata": {
        "id": "JUijSxpb-7LO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Initialize the text splitter with specific chunk size and overlap\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
        ")\n",
        "all_splits = text_splitter.split_documents(all_docs)\n",
        "\n",
        "print(f\"Total splits created: {len(all_splits)}\")\n",
        "print(all_splits[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sbLJhuBofn0m",
        "outputId": "6766df39-417b-4170-d4d0-0161a93d7533"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total splits created: 4204\n",
            "page_content='﻿Fund Name: ﻿Fund Name\n",
            "Fund Manager Name: Fund Manager Name\n",
            "ISIN: ISIN\n",
            "Region: Region\n",
            "Sector: Sector\n",
            "2023 RE participants: 2023 RE participants\n",
            "Ticker_B: Ticker_B\n",
            "Ticker: Ticker\n",
            "2019-01: 2019-01\n",
            "2019-02: 2019-02\n",
            "2019-03: 2019-03\n",
            "2019-04: 2019-04\n",
            "2019-05: 2019-05\n",
            "2019-06: 2019-06\n",
            "2019-07: 2019-07\n",
            "2019-08: 2019-08\n",
            "2019-09: 2019-09\n",
            "2019-10: 2019-10\n",
            "2019-11: 2019-11\n",
            "2019-12: 2019-12\n",
            "2020-01: 2020-01\n",
            "2020-02: 2020-02\n",
            "2020-03: 2020-03\n",
            "2020-04: 2020-04\n",
            "2020-05: 2020-05\n",
            "2020-06: 2020-06\n",
            "2020-07: 2020-07\n",
            "2020-08: 2020-08\n",
            "2020-09: 2020-09\n",
            "2020-10: 2020-10\n",
            "2020-11: 2020-11\n",
            "2020-12: 2020-12\n",
            "2021-01: 2021-01\n",
            "2021-02: 2021-02\n",
            "2021-03: 2021-03\n",
            "2021-04: 2021-04\n",
            "2021-05: 2021-05\n",
            "2021-06: 2021-06\n",
            "2021-07: 2021-07\n",
            "2021-08: 2021-08\n",
            "2021-09: 2021-09\n",
            "2021-10: 2021-10\n",
            "2021-11: 2021-11\n",
            "2021-12: 2021-12\n",
            "2022-01: 2022-01\n",
            "2022-02: 2022-02\n",
            "2022-03: 2022-03\n",
            "2022-04: 2022-04\n",
            "2022-05: 2022-05\n",
            "2022-06: 2022-06\n",
            "2022-07: 2022-07\n",
            "2022-08: 2022-08\n",
            "2022-09: 2022-09\n",
            "2022-10: 2022-10\n",
            "2022-11: 2022-11\n",
            "2022-12: 2022-12' metadata={'source': '\\ufeffFund Name', 'row': 0, 'start_index': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store document and embedding to vector database"
      ],
      "metadata": {
        "id": "TgGp4Uni--PC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "import time\n",
        "\n",
        "# Initialize the embeddings\n",
        "embedding = OpenAIEmbeddings(model='text-embedding-3-small')\n",
        "\n",
        "# Initialize the vector store for storing document embeddings\n",
        "vectorstore = Chroma(\n",
        "    collection_name=\"my_collection\",\n",
        "    embedding_function=embedding,\n",
        "    persist_directory=\"./chroma_db\"\n",
        ")\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "# Add document splits to the vector store in batches\n",
        "for i in range(0, len(all_splits), batch_size):\n",
        "    batch = all_splits[i: i + batch_size]\n",
        "    vectorstore.add_documents(batch)\n",
        "    time.sleep(1)\n"
      ],
      "metadata": {
        "id": "qtYO5Kcffqca"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similarity search"
      ],
      "metadata": {
        "id": "no6LXWyU_Nnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import spatial\n",
        "\n",
        "# Testing question\n",
        "# question = \"What is global investor expand engagement?\"\n",
        "question = \"Which fund in the north america region showed the strongest growth in 2021-2024?\"\n",
        "\n",
        "# Create a retriever object to search for similar documents\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "\n",
        "# Retrieve documents relevant to the question\n",
        "retrieved_docs = retriever.invoke(question)\n",
        "\n",
        "print(f\"Total documents retrieved: {len(retrieved_docs)}\")\n",
        "# print(retrieved_docs[0])\n",
        "\n",
        "# Calculate and print similarity scores\n",
        "question_embedding = embedding.embed_query(question)  # Embed the question\n",
        "for i in range(len(retrieved_docs)):\n",
        "    doc_embedding = embedding.embed_documents([retrieved_docs[i].page_content])[0]  # Embed the document\n",
        "    similarity = 1 - spatial.distance.cosine(question_embedding, doc_embedding)  # Calculate cosine similarity\n",
        "    print(f\"Document {i+1} (Similarity: {similarity:.4f}):\\n{retrieved_docs[i].page_content}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rLnCNfjsfsx2",
        "outputId": "75b4abd1-b53c-4f4b-dfd5-82bb54119161"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total documents retrieved: 3\n",
            "Document 1 (Similarity: 0.5487):\n",
            "﻿Fund Name: Safehold Inc\n",
            "Fund Manager Name: Safehold Inc\n",
            "ISIN: US78645L1008\n",
            "Region: North America\n",
            "Sector: Other\n",
            "2023 RE participants: No\n",
            "Ticker_B: SAFE\n",
            "Ticker: SAFE\n",
            "2019-01: 46.68029785\n",
            "2019-02: 42.59151077\n",
            "2019-03: 40.98520279\n",
            "2019-04: 42.20210266\n",
            "2019-05: 53.59228897\n",
            "2019-06: 60.45560837\n",
            "2019-07: 64.25233459\n",
            "2019-08: 62.30529785\n",
            "2019-09: 63.52219772\n",
            "2019-10: 63.32749176\n",
            "2019-11: 63.23014069\n",
            "2019-12: 70.62889099\n",
            "2020-01: 70.87227631\n",
            "2020-02: 73.64680481\n",
            "2020-03: 51.64524841\n",
            "2020-04: 48.77336502\n",
            "2020-05: 53.20288086\n",
            "2020-06: 59.96884537\n",
            "2020-07: 56.51285172\n",
            "2020-08: 60.2609024\n",
            "2020-09: 57.48637009\n",
            "2020-10: 57.43769455\n",
            "2020-11: 68.63317871\n",
            "2020-12: 72.28388214\n",
            "2021-01: 73.89019012\n",
            "2021-02: 86.25389099\n",
            "2021-03: 86.54595184\n",
            "2021-04: 90.09929657\n",
            "2021-05: 81.82437897\n",
            "2021-06: 100.9053726\n",
            "2021-07: 117.9419785\n",
            "2021-08: 128.7480469\n",
            "2021-09: 122.0794373\n",
            "2021-10: 122.8582535\n",
            "2021-11: 118.477417\n",
            "2021-12: 125.7301407\n",
            "2022-01: 104.5074005\n",
            "2022-02: 122.2741394\n",
            "2022-03: 113.9505463\n",
            "\n",
            "Document 2 (Similarity: 0.5278):\n",
            "﻿Fund Name: Global Self Storage\n",
            "Fund Manager Name: Global Self Storage\n",
            "ISIN: US37955N1063\n",
            "Region: North America\n",
            "Sector: Other\n",
            "2023 RE participants: No\n",
            "Ticker_B: SELF\n",
            "Ticker: SELF\n",
            "2019-01: 4\n",
            "2019-02: 3.950000048\n",
            "2019-03: 3.859999895\n",
            "2019-04: 3.839999914\n",
            "2019-05: 3.670000076\n",
            "2019-06: 3.75999999\n",
            "2019-07: 4.159999847\n",
            "2019-08: 4.389999866\n",
            "2019-09: 4.760000229\n",
            "2019-10: 4.179999828\n",
            "2019-11: 4.260000229\n",
            "2019-12: 4.300000191\n",
            "2020-01: 4.190000057\n",
            "2020-02: 4.309999943\n",
            "2020-03: 3.50999999\n",
            "2020-04: 3.970000029\n",
            "2020-05: 4.159999847\n",
            "2020-06: 3.849999905\n",
            "2020-07: 3.74000001\n",
            "2020-08: 3.980000019\n",
            "2020-09: 4.010000229\n",
            "2020-10: 3.950000048\n",
            "2020-11: 3.980000019\n",
            "2020-12: 4.010000229\n",
            "2021-01: 4.059999943\n",
            "2021-02: 4.409999847\n",
            "2021-03: 4.760000229\n",
            "2021-04: 4.96999979\n",
            "2021-05: 5.489999771\n",
            "2021-06: 5.210000038\n",
            "2021-07: 5.139999866\n",
            "2021-08: 5.429999828\n",
            "2021-09: 5.150000095\n",
            "2021-10: 5.090000153\n",
            "2021-11: 5.360000134\n",
            "2021-12: 5.699999809\n",
            "2022-01: 6.150000095\n",
            "2022-02: 5.699999809\n",
            "2022-03: 5.599999905\n",
            "\n",
            "Document 3 (Similarity: 0.5252):\n",
            "﻿Fund Name: Armada Hoffler Properties Inc\n",
            "Fund Manager Name: Armada Hoffler Properties Inc\n",
            "ISIN: US04208T1088\n",
            "Region: North America\n",
            "Sector: Other\n",
            "2023 RE participants: No\n",
            "Ticker_B: AHH\n",
            "Ticker: AHH\n",
            "2019-01: 15.02000046\n",
            "2019-02: 15.30000019\n",
            "2019-03: 15.59000015\n",
            "2019-04: 16.14999962\n",
            "2019-05: 16.5\n",
            "2019-06: 16.54999924\n",
            "2019-07: 16.93000031\n",
            "2019-08: 17.34000015\n",
            "2019-09: 18.09000015\n",
            "2019-10: 18.73999977\n",
            "2019-11: 18.05999947\n",
            "2019-12: 18.35000038\n",
            "2020-01: 18.34000015\n",
            "2020-02: 16.76000023\n",
            "2020-03: 10.69999981\n",
            "2020-04: 9.609999657\n",
            "2020-05: 8.619999886\n",
            "2020-06: 9.949999809\n",
            "2020-07: 9.640000343\n",
            "2020-08: 10.10000038\n",
            "2020-09: 9.260000229\n",
            "2020-10: 9.010000229\n",
            "2020-11: 10.60999966\n",
            "2020-12: 11.22000027\n",
            "2021-01: 10.75\n",
            "2021-02: 12.90999985\n",
            "2021-03: 12.53999996\n",
            "2021-04: 13.63000011\n",
            "2021-05: 13.27000046\n",
            "2021-06: 13.28999996\n",
            "2021-07: 13\n",
            "2021-08: 13.43000031\n",
            "2021-09: 13.36999989\n",
            "2021-10: 13.71000004\n",
            "2021-11: 13.94999981\n",
            "2021-12: 15.22000027\n",
            "2022-01: 14.02999973\n",
            "2022-02: 14.68000031\n",
            "2022-03: 14.60000038\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reply generation"
      ],
      "metadata": {
        "id": "wmLsEXjv_QQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "\n",
        "# Load a predefined prompt from the Langchain hub\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "# Generate example messages based on the retrieved documents and the question\n",
        "example_messages = prompt.invoke(\n",
        "    {\"context\": \"{retrieved_docs}\", \"question\": \"{your_question}\", \"reference\": \"{source}\"}\n",
        ").to_messages()\n",
        "\n",
        "print(example_messages[0].content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igeIhNNxfwyU",
        "outputId": "d1ad6fa6-d2ee-4f0b-c7df-ac3cfbf39180"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: {your_question} \n",
            "Context: {retrieved_docs} \n",
            "Answer:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Customize the prompt"
      ],
      "metadata": {
        "id": "x9JmsHQ0_SU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# Define a custom prompt template\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "Use three sentences maximum and keep the answer as concise as possible.\n",
        "Always say \"Thank you for asking! | Red Team - TABC Interns\" at the end of the answer and followed by the reference contains URL source (if it doesn't contain URL don't put any reference).\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Helpful Answer:\n",
        "\n",
        "Reference:\n",
        "- {source_column}\"\"\"\n",
        "\n",
        "# Create a prompt object from the template\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "example_messages = prompt.invoke(\n",
        "    {\n",
        "        \"context\": retrieved_docs[0].page_content,\n",
        "        \"question\": question,\n",
        "        # \"source_file\": files[0],  # Replace with actual source file\n",
        "        \"source_column\": 'URL'  # Replace with actual source column\n",
        "    }\n",
        ").to_messages()\n",
        "\n",
        "print(example_messages[0].content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNndqitdfxiL",
        "outputId": "fd72d645-28ce-49d7-fea8-06c4457c54fc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use the following pieces of context to answer the question at the end.\n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "Use three sentences maximum and keep the answer as concise as possible.\n",
            "Always say \"Thank you for asking! | Red Team - TABC Interns\" at the end of the answer and followed by the reference contains URL source (if it doesn't contain URL don't put any reference).\n",
            "\n",
            "﻿Fund Name: Safehold Inc\n",
            "Fund Manager Name: Safehold Inc\n",
            "ISIN: US78645L1008\n",
            "Region: North America\n",
            "Sector: Other\n",
            "2023 RE participants: No\n",
            "Ticker_B: SAFE\n",
            "Ticker: SAFE\n",
            "2019-01: 46.68029785\n",
            "2019-02: 42.59151077\n",
            "2019-03: 40.98520279\n",
            "2019-04: 42.20210266\n",
            "2019-05: 53.59228897\n",
            "2019-06: 60.45560837\n",
            "2019-07: 64.25233459\n",
            "2019-08: 62.30529785\n",
            "2019-09: 63.52219772\n",
            "2019-10: 63.32749176\n",
            "2019-11: 63.23014069\n",
            "2019-12: 70.62889099\n",
            "2020-01: 70.87227631\n",
            "2020-02: 73.64680481\n",
            "2020-03: 51.64524841\n",
            "2020-04: 48.77336502\n",
            "2020-05: 53.20288086\n",
            "2020-06: 59.96884537\n",
            "2020-07: 56.51285172\n",
            "2020-08: 60.2609024\n",
            "2020-09: 57.48637009\n",
            "2020-10: 57.43769455\n",
            "2020-11: 68.63317871\n",
            "2020-12: 72.28388214\n",
            "2021-01: 73.89019012\n",
            "2021-02: 86.25389099\n",
            "2021-03: 86.54595184\n",
            "2021-04: 90.09929657\n",
            "2021-05: 81.82437897\n",
            "2021-06: 100.9053726\n",
            "2021-07: 117.9419785\n",
            "2021-08: 128.7480469\n",
            "2021-09: 122.0794373\n",
            "2021-10: 122.8582535\n",
            "2021-11: 118.477417\n",
            "2021-12: 125.7301407\n",
            "2022-01: 104.5074005\n",
            "2022-02: 122.2741394\n",
            "2022-03: 113.9505463\n",
            "\n",
            "Question: Which fund in the north america region showed the strongest growth in 2021-2024?\n",
            "\n",
            "Helpful Answer:\n",
            "\n",
            "Reference:\n",
            "- URL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LCEL (Langchain Expression Language)"
      ],
      "metadata": {
        "id": "qNSw_syw_VI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# Function to format documents for the prompt\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# Create a RAG (Retrieval-Augmented Generation) chain\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": retriever | format_docs,\n",
        "        \"question\": RunnablePassthrough(),\n",
        "        # \"source_file\": lambda x: files[0],  # Provide source_file\n",
        "        \"source_column\": lambda x: \"URL\"  # Provide source_column\n",
        "    }\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Stream the response from the RAG chain for the given question\n",
        "for chunk in rag_chain.stream(question):\n",
        "    print(chunk, end=\"\", flush=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50hXraezf0Do",
        "outputId": "d9306931-52cd-4b2e-a24e-e102a7e04602"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fund that showed the strongest growth in the North America region from 2021 to 2022 is Safehold Inc, with its price increasing from 73.89019012 in January 2021 to 113.9505463 in March 2022.\n",
            "\n",
            "Thank you for asking! | Red Team - TABC Interns"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio interface setup"
      ],
      "metadata": {
        "id": "egctzsDJ_a3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import datetime\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# Function to log interactions to a CSV file\n",
        "def log_interaction_csv(user_message, bot_message, satisfaction_message=None, log_file=\"chat_log.csv\"):\n",
        "    file_exists = os.path.isfile(log_file)\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    try:\n",
        "        with open(log_file, \"a+\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "            writer = csv.writer(file)\n",
        "            if not file_exists:\n",
        "                writer.writerow([\"Timestamp\", \"Query\", \"Answer\", \"Satisfaction\"])\n",
        "\n",
        "            if satisfaction_message:\n",
        "                file.seek(0)\n",
        "                rows = list(csv.reader(file))\n",
        "                if len(rows) > 1:\n",
        "                    rows[-1][-1] = satisfaction_message\n",
        "                    file.seek(0)\n",
        "                    file.truncate()\n",
        "                    writer.writerows(rows)\n",
        "            else:\n",
        "                writer.writerow([timestamp, user_message, bot_message, \"\"])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing to file: {e}\")\n",
        "\n",
        "# Function to generate a chatbot response\n",
        "def chatbot_response(question):\n",
        "    response = \"\"\n",
        "    for chunk in rag_chain.stream(question):\n",
        "        response += chunk\n",
        "    return response\n",
        "\n",
        "# Function to handle user satisfactions on responses\n",
        "def satisfaction(data: gr.LikeData):\n",
        "    satisfaction_message = \"Liked\" if data.liked else \"Disliked\"\n",
        "    log_interaction_csv(\"\", \"\", satisfaction_message)\n",
        "    print(satisfaction_message)\n",
        "\n",
        "# Gradio interface setup\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## TABC - ChatBot V.0.1\\nThe database of chatbot (V.0.1) now contains detailed information about the GRESB foundation, its impact, and sustainability focus.\")\n",
        "    chatbot = gr.Chatbot(label=\"Latest database update (2024/07/30)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        txt = gr.Textbox(show_label=False, placeholder=\"Enter your question here...\")\n",
        "        submit_btn = gr.Button(\"Send\")\n",
        "        retry_btn = gr.Button(\"Regenerate\") # Add a retry button\n",
        "\n",
        "        # Function to handle user message input\n",
        "        def user_message(message, history):\n",
        "            history.append((message, None))\n",
        "            return history, \"\"\n",
        "\n",
        "        # Function to handle bot response\n",
        "        def bot_response(history):\n",
        "            user_message = history[-1][0]\n",
        "            bot_message = chatbot_response(user_message)\n",
        "            history[-1] = (user_message, bot_message)\n",
        "\n",
        "            # Log the interaction\n",
        "            log_interaction_csv(user_message, bot_message)\n",
        "\n",
        "            return history\n",
        "\n",
        "        # Function to handle retry\n",
        "        def retry(history):\n",
        "            if history:\n",
        "                last_question = history[-1][0]  # Get the last question\n",
        "                history.pop() # Remove the last interaction\n",
        "                # Re-run the last question by triggering user_message and bot_response\n",
        "                history, _ = user_message(last_question, history)\n",
        "                history = bot_response(history)\n",
        "            return history, \"\"\n",
        "\n",
        "    # Handle the submit, click, and retry events\n",
        "    txt.submit(user_message, [txt, chatbot], [chatbot, txt], queue=False).then(\n",
        "        bot_response, chatbot, chatbot\n",
        "    )\n",
        "    submit_btn.click(user_message, [txt, chatbot], [chatbot, txt], queue=False).then(\n",
        "        bot_response, chatbot, chatbot\n",
        "    )\n",
        "    retry_btn.click(retry, chatbot, [chatbot, txt])\n",
        "    # Add the voting functionality to the chatbot\n",
        "    chatbot.like(satisfaction, None, None)\n",
        "\n",
        "# Launch the Gradio interface\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "hlTdV8RSf2Pj",
        "outputId": "f9dcdc0b-a215-4e03-fae6-d6fee9745446"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://7cb81ded52291d1f30.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7cb81ded52291d1f30.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of examples\n",
        "\"\"\"\n",
        "1. Tell me information about global investor expand engagement?\n",
        "2. Give me some information about ticker named \"REG\"\n",
        "3. How did [Fund Name X] perform in the first quarter of 2020?\" (Replace [Fund Name X] with an actual fund from your data)\n",
        "4. Which fund in the \"north america\" region showed the strongest growth in 2021?\n",
        "5. What was the average performance of \"Office\" funds in the second half of 2022?\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "1FMwVPKzxgfJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "395e54c6-6145-4739-f121-bc6da43c258d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1. Tell me information about global investor expand engagement?\\n2. Give me some information about ticker named \"REG\"\\n3. How did [Fund Name X] perform in the first quarter of 2020?\" (Replace [Fund Name X] with an actual fund from your data)\\n4. Which fund in the \"north america\" region showed the strongest growth in 2021?\\n5. What was the average performance of \"Office\" funds in the second half of 2022?\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Documentations\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h5jg9eLQj3CP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Documentations\n",
        "\n",
        "'''\n",
        "IMPROVEMENT\n",
        "1. Enhanced the database by incorporating additional datasets into a single directory.\n",
        "2. Expanded the focus column to encompass each category provided in the CSV file.\n",
        "3. Modified the prompt to enhance the output by including the source URL (mimicking Gemini and Co-pilot).\n",
        "4. Designed the chatbot interface to be more conversational-based.\n",
        "5. Added a history function to regenerate answers if the user is not satisfied.\n",
        "6. Implemented a satisfaction measurement system.\n",
        "7. Logged activity output to track conversations and user satisfaction.\n",
        "\n",
        "LIMITATIONS\n",
        "1. The performance in answering questions is better on the text-based dataset of the source.\n",
        "2. Specificity is required to answer questions on the financial dataset which has a greater number of data points.\n",
        "3. It is important to note that history is not equal to memory. In some cases, the memory function does not perform well enough to answer every question and make it conversational.\n",
        "4. There is a bug in the satisfaction system that is only detected in the last interaction.\n",
        "\n",
        "PLANS FOR THE FOLLOWING WORK\n",
        "1. Solve the limitations.\n",
        "2. Enhance the multi-format response, including graph visualization.\n",
        "3. ...\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "collapsed": true,
        "id": "wRdFpr00weNs",
        "outputId": "b5182d23-0d10-4486-f71d-5a523ec5e35c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nIMPROVEMENT\\n1. Improved a larger database with combining more datasets into a folder. \\n2. Enlarged the focus column to each category provided by the CSV file.\\n3. Modified the prompt to improve the output with source of URL (mimicking Gemini and Co-pilot).\\n4. Visualized the chatbot interface with coversational-based chatbot.\\n5. Add the history function to regenerate the answer, if user is not satisfied.\\n6. Satisfaction measurement.\\n7. Log activity output to track the conversation and the satisfaction.\\n\\nLIMITATIONS\\n1. The answering performance shows better from the text-based dataset.\\n2. To answer the question on the financial dataset (that has more number), it has to bevery specific.\\n3. History ≠ Memory, in some cases, the memory functions is not perform enough good to answer every questio and make it conversationally.\\n4. Bug on satisfaction system that only detect on last interaction.\\n\\nPLANS FOR THE FOLLOWING WORK\\n1. Solve the limitations.\\n2. Improve the multiformat answer,  such as visulaizing the graph.\\n3. ...\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "frV589AL19ty"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}